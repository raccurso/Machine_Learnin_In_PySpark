{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning con PySpark\n",
    "\n",
    "#### Autor: Rodrigo Accurso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import de las librerias y lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import isnan, when, count, countDistinct\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes, LinearSVC, RandomForestClassifier\n",
    "from pyspark.ml.feature import ChiSqSelector, PCA\n",
    "import numpy as np\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"PracticaFinal\")\n",
    "sql = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470\n",
      "35\n",
      "[Row(Age=41, Attrition='Yes', BusinessTravel='Travel_Rarely', DailyRate=1102, Department='Sales', DistanceFromHome=1, Education=2, EducationField='Life Sciences', EmployeeCount=1, EmployeeNumber=1, EnvironmentSatisfaction=2, Gender='Female', HourlyRate=94, JobInvolvement=3, JobLevel=2, JobRole='Sales Executive', JobSatisfaction=4, MaritalStatus='Single', MonthlyIncome=5993, MonthlyRate=19479, NumCompaniesWorked=8, Over18='Y', OverTime='Yes', PercentSalaryHike=11, PerformanceRating=3, RelationshipSatisfaction=1, StandardHours=80, StockOptionLevel=0, TotalWorkingYears=8, TrainingTimesLastYear=0, WorkLifeBalance=1, YearsAtCompany=6, YearsInCurrentRole=4, YearsSinceLastPromotion=0, YearsWithCurrManager=5), Row(Age=49, Attrition='No', BusinessTravel='Travel_Frequently', DailyRate=279, Department='Research & Development', DistanceFromHome=8, Education=1, EducationField='Life Sciences', EmployeeCount=1, EmployeeNumber=2, EnvironmentSatisfaction=3, Gender='Male', HourlyRate=61, JobInvolvement=2, JobLevel=2, JobRole='Research Scientist', JobSatisfaction=2, MaritalStatus='Married', MonthlyIncome=5130, MonthlyRate=24907, NumCompaniesWorked=1, Over18='Y', OverTime='No', PercentSalaryHike=23, PerformanceRating=4, RelationshipSatisfaction=4, StandardHours=80, StockOptionLevel=1, TotalWorkingYears=10, TrainingTimesLastYear=3, WorkLifeBalance=3, YearsAtCompany=10, YearsInCurrentRole=7, YearsSinceLastPromotion=1, YearsWithCurrManager=7)]\n"
     ]
    }
   ],
   "source": [
    "df = sql.read.csv('HR.Employee.Attrition.csv', sep=\",\", inferSchema=True, header=True)\n",
    "print(df.count())\n",
    "print(len(df.columns))\n",
    "print(df.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Obtengo los tipos de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Attrition: string (nullable = true)\n",
      " |-- BusinessTravel: string (nullable = true)\n",
      " |-- DailyRate: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- DistanceFromHome: integer (nullable = true)\n",
      " |-- Education: integer (nullable = true)\n",
      " |-- EducationField: string (nullable = true)\n",
      " |-- EmployeeCount: integer (nullable = true)\n",
      " |-- EmployeeNumber: integer (nullable = true)\n",
      " |-- EnvironmentSatisfaction: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- HourlyRate: integer (nullable = true)\n",
      " |-- JobInvolvement: integer (nullable = true)\n",
      " |-- JobLevel: integer (nullable = true)\n",
      " |-- JobRole: string (nullable = true)\n",
      " |-- JobSatisfaction: integer (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- MonthlyIncome: integer (nullable = true)\n",
      " |-- MonthlyRate: integer (nullable = true)\n",
      " |-- NumCompaniesWorked: integer (nullable = true)\n",
      " |-- Over18: string (nullable = true)\n",
      " |-- OverTime: string (nullable = true)\n",
      " |-- PercentSalaryHike: integer (nullable = true)\n",
      " |-- PerformanceRating: integer (nullable = true)\n",
      " |-- RelationshipSatisfaction: integer (nullable = true)\n",
      " |-- StandardHours: integer (nullable = true)\n",
      " |-- StockOptionLevel: integer (nullable = true)\n",
      " |-- TotalWorkingYears: integer (nullable = true)\n",
      " |-- TrainingTimesLastYear: integer (nullable = true)\n",
      " |-- WorkLifeBalance: integer (nullable = true)\n",
      " |-- YearsAtCompany: integer (nullable = true)\n",
      " |-- YearsInCurrentRole: integer (nullable = true)\n",
      " |-- YearsSinceLastPromotion: integer (nullable = true)\n",
      " |-- YearsWithCurrManager: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Verifico la presencia de NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Age=0, Attrition=0, BusinessTravel=0, DailyRate=0, Department=0, DistanceFromHome=0, Education=0, EducationField=0, EmployeeCount=0, EmployeeNumber=0, EnvironmentSatisfaction=0, Gender=0, HourlyRate=0, JobInvolvement=0, JobLevel=0, JobRole=0, JobSatisfaction=0, MaritalStatus=0, MonthlyIncome=0, MonthlyRate=0, NumCompaniesWorked=0, Over18=0, OverTime=0, PercentSalaryHike=0, PerformanceRating=0, RelationshipSatisfaction=0, StandardHours=0, StockOptionLevel=0, TotalWorkingYears=0, TrainingTimesLastYear=0, WorkLifeBalance=0, YearsAtCompany=0, YearsInCurrentRole=0, YearsSinceLastPromotion=0, YearsWithCurrManager=0)]\n"
     ]
    }
   ],
   "source": [
    "df_na = df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).collect()\n",
    "print(df_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ingeniería de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Elimino las columnas con valores diferentes en todas las filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Age='F', Attrition='F', BusinessTravel='F', DailyRate='F', Department='F', DistanceFromHome='F', Education='F', EducationField='F', EmployeeCount='F', EmployeeNumber='T', EnvironmentSatisfaction='F', Gender='F', HourlyRate='F', JobInvolvement='F', JobLevel='F', JobRole='F', JobSatisfaction='F', MaritalStatus='F', MonthlyIncome='F', MonthlyRate='F', NumCompaniesWorked='F', Over18='F', OverTime='F', PercentSalaryHike='F', PerformanceRating='F', RelationshipSatisfaction='F', StandardHours='F', StockOptionLevel='F', TotalWorkingYears='F', TrainingTimesLastYear='F', WorkLifeBalance='F', YearsAtCompany='F', YearsInCurrentRole='F', YearsSinceLastPromotion='F', YearsWithCurrManager='F')]\n"
     ]
    }
   ],
   "source": [
    "df_unique = df.select([when(countDistinct(column) == df.count(), 'T').otherwise('F').alias(column) for column in df.columns]) \\\n",
    "                .collect()\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('EmployeeNumber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Elimino las columnas con valor igual en todas las filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Age='F', Attrition='F', BusinessTravel='F', DailyRate='F', Department='F', DistanceFromHome='F', Education='F', EducationField='F', EmployeeCount='T', EnvironmentSatisfaction='F', Gender='F', HourlyRate='F', JobInvolvement='F', JobLevel='F', JobRole='F', JobSatisfaction='F', MaritalStatus='F', MonthlyIncome='F', MonthlyRate='F', NumCompaniesWorked='F', Over18='T', OverTime='F', PercentSalaryHike='F', PerformanceRating='F', RelationshipSatisfaction='F', StandardHours='T', StockOptionLevel='F', TotalWorkingYears='F', TrainingTimesLastYear='F', WorkLifeBalance='F', YearsAtCompany='F', YearsInCurrentRole='F', YearsSinceLastPromotion='F', YearsWithCurrManager='F')]\n"
     ]
    }
   ],
   "source": [
    "df_same = df.select([when(countDistinct(column) == 1, 'T').otherwise('F').alias(column) for column in df.columns]) \\\n",
    "                .collect()\n",
    "print(df_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('EmployeeCount')\n",
    "df = df.drop('Over18')\n",
    "df = df.drop('StandardHours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Convierto las variables alfanumericas en numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'OverTime']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_stages = []\n",
    "string_cols = [x[0] for x in df.dtypes if (x[1] == 'string') & (x[0] != 'Attrition')]\n",
    "string_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'DailyRate',\n",
       " 'DistanceFromHome',\n",
       " 'Education',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'HourlyRate',\n",
       " 'JobInvolvement',\n",
       " 'JobLevel',\n",
       " 'JobSatisfaction',\n",
       " 'MonthlyIncome',\n",
       " 'MonthlyRate',\n",
       " 'NumCompaniesWorked',\n",
       " 'PercentSalaryHike',\n",
       " 'PerformanceRating',\n",
       " 'RelationshipSatisfaction',\n",
       " 'StockOptionLevel',\n",
       " 'TotalWorkingYears',\n",
       " 'TrainingTimesLastYear',\n",
       " 'WorkLifeBalance',\n",
       " 'YearsAtCompany',\n",
       " 'YearsInCurrentRole',\n",
       " 'YearsSinceLastPromotion',\n",
       " 'YearsWithCurrManager']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = [x[0] for x in df.dtypes if x[1] != 'string']\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in string_cols:\n",
    "    indexer = StringIndexer(inputCol = col, outputCol = col + 'Index')\n",
    "    main_stages += [indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformo la variable target Attrition separadamente porque no debe estar en el pipeline\n",
    "indexer = StringIndexer(inputCol = 'Attrition', outputCol = 'label')\n",
    "indexer = indexer.fit(df)\n",
    "df = indexer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Aplico el One Hot Encoding en las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Department', 'EducationField','JobRole','MaritalStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    encoder = OneHotEncoderEstimator(inputCols = [col + 'Index'], outputCols = [col + 'Vec'])\n",
    "    main_stages += [encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Genero el vector necesario para entrenar los modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables numericas\n",
    "assemblerInputs = numeric_cols\n",
    "# Variables alfanumericas a las que no aplique el one hot encoding\n",
    "assemblerInputs = assemblerInputs + [col + 'Index' for col in (set(string_cols) - set(cat_cols))]\n",
    "# Variables alfanumericas a las que aplique el one hot encoding\n",
    "assemblerInputs = assemblerInputs + [col + 'Vec' for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol='features')\n",
    "main_stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Normalizacion de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "main_stages += [scaler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 Selección de variables por Chi-cuadrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selección con p-valor <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq_selector_05 = ChiSqSelector(fpr=0.05, selectorType='fpr',featuresCol='scaledFeatures',\n",
    "                         outputCol='selectedFeatures', labelCol='label')\n",
    "chisq_stages_05 = main_stages[:]\n",
    "chisq_stages_05 += [chisq_selector_05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selección con p-valor <= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq_selector_01 = ChiSqSelector(fpr=0.01, selectorType='fpr',featuresCol='scaledFeatures',\n",
    "                         outputCol='selectedFeatures', labelCol='label')\n",
    "chisq_stages_01 = main_stages[:]\n",
    "chisq_stages_01 += [chisq_selector_01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Extracción de variables con PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción con k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_5 = PCA(k=5, inputCol='scaledFeatures', outputCol='pcaFeatures')\n",
    "pca_stages_5 = main_stages[:]\n",
    "pca_stages_5 += [pca_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción con k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_10 = PCA(k=10, inputCol='scaledFeatures', outputCol='pcaFeatures')\n",
    "pca_stages_10 = main_stages[:]\n",
    "pca_stages_10 += [pca_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayes Ingénuo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Creo diccionarios con la información necesaria para ejecutar todos los casos por cada aloritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stages = {'BASE': main_stages,\n",
    "              'CHI-CUADRADO-05': chisq_stages_05,\n",
    "              'CHI-CUADRADO-01': chisq_stages_01}\n",
    "\n",
    "feature_field = {'BASE': 'scaledFeatures',\n",
    "                 'CHI-CUADRADO-05': 'selectedFeatures',\n",
    "                 'CHI-CUADRADO-01': 'selectedFeatures'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: No puedo utilizar PCA porque el Bayes Ingénuo no acepta números negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Creo una función que evalúa el algoritmo con los hiper-parámetros en entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evualua_modelo(input_smoothing):\n",
    "    for sel_stages in all_stages:\n",
    "        \n",
    "        print('CASO ' + sel_stages)\n",
    "        print('------------------------')\n",
    "        \n",
    "        # Creo el algoritmo de clasificación\n",
    "        nb = NaiveBayes(featuresCol=feature_field.get(sel_stages), labelCol='label')    \n",
    "        print('Features: ' + feature_field.get(sel_stages))\n",
    "        \n",
    "        # Construyo el pipeline completo\n",
    "        nb_stages = all_stages.get(sel_stages)[:]\n",
    "        nb_stages += [nb]\n",
    "        pipeline = Pipeline(stages=nb_stages)\n",
    "\n",
    "        # Creo el grid de hiper-parámetros\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                     .addGrid(nb.smoothing, input_smoothing.get(sel_stages))\n",
    "                     .addGrid(nb.modelType, ['multinomial'])\n",
    "                     .build())  \n",
    "\n",
    "        # Ejecuto la validación cruzada con los hiperparámetros seleccionados\n",
    "        cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, \n",
    "                            evaluator=evaluator, numFolds=5)\n",
    "        pipelineModel = cv.fit(df)    \n",
    "        \n",
    "        # Muestro los resultados\n",
    "        print('Hiper-parámetros óptimos:')\n",
    "        print('smoothing = ' + str(pipelineModel.bestModel.stages[-1]._java_obj.getSmoothing()))\n",
    "        print('ROC-AUC = ' + str(np.mean(pipelineModel.avgMetrics)))\n",
    "        print('')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Evalúo Bayes Ingénuo con lista amplia de hiper-parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASO BASE\n",
      "------------------------\n",
      "Features: scaledFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "smoothing = 0.0\n",
      "ROC-AUC = 0.6305925693344068\n",
      "\n",
      "CASO CHI-CUADRADO-05\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "smoothing = 0.0\n",
      "ROC-AUC = 0.6314127561352433\n",
      "\n",
      "CASO CHI-CUADRADO-01\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "smoothing = 0.0\n",
      "ROC-AUC = 0.6334527955217494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_smoothing = {'BASE': [0., 0.5, 1.0],\n",
    "                   'CHI-CUADRADO-05': [0., 0.5, 1.0],\n",
    "                   'CHI-CUADRADO-01':  [0., 0.5, 1.0]}                   \n",
    "    \n",
    "evualua_modelo(param_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Evalúo Bayes Ingénuo con fine-tuning de hiper-parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASO BASE\n",
      "------------------------\n",
      "Features: scaledFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "smoothing = 0.0\n",
      "ROC-AUC = 0.6310011695464576\n",
      "\n",
      "CASO CHI-CUADRADO-05\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "smoothing = 0.0\n",
      "ROC-AUC = 0.6320403657626575\n",
      "\n",
      "CASO CHI-CUADRADO-01\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "smoothing = 0.0\n",
      "ROC-AUC = 0.6338857821851124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_smoothing = {'BASE': [0., 0.05, .1],\n",
    "                   'CHI-CUADRADO-05': [0., 0.05, .1],\n",
    "                   'CHI-CUADRADO-01':  [0., 0.05, .1]}                   \n",
    "    \n",
    "evualua_modelo(param_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El único hiper-parámetro configurable es el Smoothing, que es la suavización de probabilidades a través del Estimador de Laplace. El valor óptimo es 0 porque en el dataset no existe el caso en que el valor de una variable categórica no se esté en una de las dos clases.\n",
    "\n",
    "La ejecución con selección de variables con p-valor <= 0.01 obtuvo el mejor resultado. Supongo que el motivo es la no independencia de variables que existe en el dataset, mientras que Bayes Ingénuo asume una completa independencia.\n",
    "\n",
    "ROC-AUC = 0.6339"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Creo diccionarios con la información necesaria para ejecutar todos los casos por cada aloritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stages = {'BASE': main_stages,\n",
    "              'CHI-CUADRADO-05': chisq_stages_05,\n",
    "              'CHI-CUADRADO-01': chisq_stages_01,\n",
    "              'PCA-k5': pca_stages_5,\n",
    "              'PCA-k10': pca_stages_10}\n",
    "\n",
    "feature_field = {'BASE': 'scaledFeatures',\n",
    "                 'CHI-CUADRADO-05': 'selectedFeatures',\n",
    "                 'CHI-CUADRADO-01': 'selectedFeatures',\n",
    "                 'PCA-k5': 'pcaFeatures',\n",
    "                 'PCA-k10': 'pcaFeatures'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Creo una función que evalúa el algoritmo con los hiper-parámetros en entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evualua_modelo_SVM(input_regParam, input_maxIter):\n",
    "    for sel_stages in all_stages:\n",
    "        \n",
    "        print('CASO ' + sel_stages)\n",
    "        print('------------------------')\n",
    "        \n",
    "        # Creo el algoritmo de clasificación\n",
    "        svc = LinearSVC(featuresCol=feature_field.get(sel_stages), labelCol='label')    \n",
    "        print('Features: ' + feature_field.get(sel_stages))\n",
    "        \n",
    "        # Construyo el pipeline completo\n",
    "        svc_stages = all_stages.get(sel_stages)[:]\n",
    "        svc_stages += [svc]\n",
    "        pipeline = Pipeline(stages=svc_stages)\n",
    "\n",
    "        # Creo el grid de hiper-parámetros\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                     .addGrid(svc.regParam, input_regParam.get(sel_stages))\n",
    "                     .addGrid(svc.maxIter, input_maxIter.get(sel_stages))                  \n",
    "                     .build())  \n",
    "\n",
    "        # Ejecuto la validación cruzada con los hiperparámetros seleccionados\n",
    "        cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, \n",
    "                            evaluator=evaluator, numFolds=5)\n",
    "        pipelineModel = cv.fit(df)    \n",
    "        \n",
    "        # Muestro los resultados\n",
    "        print('Hiper-parámetros óptimos:')\n",
    "        print('regParam = ' + str(pipelineModel.bestModel.stages[-1]._java_obj.getRegParam()))\n",
    "        print('maxIter = ' + str(pipelineModel.bestModel.stages[-1]._java_obj.getMaxIter()))\n",
    "        print('ROC-AUC = ' + str(np.mean(pipelineModel.avgMetrics)))\n",
    "        print('')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Evalúo SVM con lista amplia de hiper-parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASO BASE\n",
      "------------------------\n",
      "Features: scaledFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.5\n",
      "maxIter = 100\n",
      "ROC-AUC = 0.8143945767212432\n",
      "\n",
      "CASO CHI-CUADRADO-05\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 1.0\n",
      "maxIter = 50\n",
      "ROC-AUC = 0.8002146337229715\n",
      "\n",
      "CASO CHI-CUADRADO-01\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.5\n",
      "maxIter = 100\n",
      "ROC-AUC = 0.798068156553817\n",
      "\n",
      "CASO PCA-k5\n",
      "------------------------\n",
      "Features: pcaFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.0\n",
      "maxIter = 10\n",
      "ROC-AUC = 0.654768298041164\n",
      "\n",
      "CASO PCA-k10\n",
      "------------------------\n",
      "Features: pcaFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.0\n",
      "maxIter = 10\n",
      "ROC-AUC = 0.7626341477018037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_regParam = {'BASE': [0., 0.5, 1.0],\n",
    "                  'CHI-CUADRADO-05': [0., 0.5, 1.0],\n",
    "                  'CHI-CUADRADO-01':  [0., 0.5, 1.0],\n",
    "                  'PCA-k5': [0., 0.5, 1.0],\n",
    "                  'PCA-k10': [0., 0.5, 1.0]}\n",
    "\n",
    "param_maxIter = {'BASE': [10, 50, 100],\n",
    "                 'CHI-CUADRADO-05': [10, 50, 100],\n",
    "                 'CHI-CUADRADO-01': [10, 50, 100],\n",
    "                 'PCA-k5': [10, 50, 100],\n",
    "                 'PCA-k10': [10, 50, 100]}\n",
    "    \n",
    "evualua_modelo_SVM(param_regParam, param_maxIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Evalúo SVM con fine-tuning de hiper-parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASO BASE\n",
      "------------------------\n",
      "Features: scaledFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.6\n",
      "maxIter = 100\n",
      "ROC-AUC = 0.8293923941436913\n",
      "\n",
      "CASO CHI-CUADRADO-05\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 1.0\n",
      "maxIter = 50\n",
      "ROC-AUC = 0.8022375679279371\n",
      "\n",
      "CASO CHI-CUADRADO-01\n",
      "------------------------\n",
      "Features: selectedFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.5\n",
      "maxIter = 80\n",
      "ROC-AUC = 0.8046145747715915\n",
      "\n",
      "CASO PCA-k5\n",
      "------------------------\n",
      "Features: pcaFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.0\n",
      "maxIter = 10\n",
      "ROC-AUC = 0.6437187105127199\n",
      "\n",
      "CASO PCA-k10\n",
      "------------------------\n",
      "Features: pcaFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "regParam = 0.1\n",
      "maxIter = 10\n",
      "ROC-AUC = 0.7625266621007054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_regParam = {'BASE': [0.4, 0.5, 0.6],\n",
    "                  'CHI-CUADRADO-05': [0.8, 0.9, 1.0],\n",
    "                  'CHI-CUADRADO-01':  [0.4, 0.5, 0.6],\n",
    "                  'PCA-k5': [0., 0.05, 0.1],\n",
    "                  'PCA-k10': [0., 0.05, 0.1]}\n",
    "\n",
    "param_maxIter = {'BASE': [80, 100, 120],\n",
    "                 'CHI-CUADRADO-05': [30, 50, 70],\n",
    "                 'CHI-CUADRADO-01': [80, 100, 120],\n",
    "                 'PCA-k5': [10, 20, 30],\n",
    "                 'PCA-k10': [10, 20, 30]}\n",
    "    \n",
    "evualua_modelo_SVM(param_regParam, param_maxIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro de regularización en SVM sirve a penalizar las clasificaciones erradas. Más alto su valor, mayor será el precio a pagar en la función de evaluación. El valor óptimo encontrado es 0.01.\n",
    "El parámetro maxIter, en cambio, limita el número de iteraciones para el entrenamiento. El valor óptimo encontrado es 120.\n",
    "\n",
    "Entre los 5 escenarios probados, obtuve mejor resultado sin aplicar selección o extracción de variables.\n",
    "\n",
    "ROC-AUC = 0.8294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Creo diccionarios con la información necesaria para ejecutar todos los casos por cada aloritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stages = {'BASE': main_stages}#,\n",
    "              #'CHI-CUADRADO-05': chisq_stages_05,\n",
    "              #'CHI-CUADRADO-01': chisq_stages_01,\n",
    "              #'PCA-k5': pca_stages_5,\n",
    "              #'PCA-k10': pca_stages_10}\n",
    "\n",
    "feature_field = {'BASE': 'scaledFeatures',\n",
    "                 'CHI-CUADRADO-05': 'selectedFeatures',\n",
    "                 'CHI-CUADRADO-01': 'selectedFeatures',\n",
    "                 'PCA-k5': 'pcaFeatures',\n",
    "                 'PCA-k10': 'pcaFeatures'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Creo una función que evalúa el algoritmo con los hiper-parámetros en entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evualua_modelo_RF(input_numTrees, input_maxDepth):\n",
    "    for sel_stages in all_stages:\n",
    "        \n",
    "        print('CASO ' + sel_stages)\n",
    "        print('------------------------')\n",
    "        \n",
    "        # Creo el algoritmo de clasificación\n",
    "        rf = RandomForestClassifier(featuresCol=feature_field.get(sel_stages), labelCol='label')\n",
    "        print('Features: ' + feature_field.get(sel_stages))\n",
    "        \n",
    "        # Construyo el pipeline completo\n",
    "        rf_stages = all_stages.get(sel_stages)[:]\n",
    "        rf_stages += [rf]\n",
    "        pipeline = Pipeline(stages=rf_stages)\n",
    "\n",
    "        # Creo el grid de hiper-parámetros\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                     .addGrid(rf.numTrees, input_numTrees.get(sel_stages))\n",
    "                     .addGrid(rf.maxDepth, input_maxDepth.get(sel_stages))                  \n",
    "                     .build())  \n",
    "\n",
    "        # Ejecuto la validación cruzada con los hiperparámetros seleccionados\n",
    "        cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, \n",
    "                            evaluator=evaluator, numFolds=5)\n",
    "        pipelineModel = cv.fit(df)    \n",
    "        \n",
    "        # Muestro los resultados\n",
    "        print('Hiper-parámetros óptimos:')\n",
    "        print('numTrees = ' + str(pipelineModel.bestModel.stages[-1]._java_obj.getNumTrees()))\n",
    "        print('maxDepth = ' + str(pipelineModel.bestModel.stages[-1]._java_obj.getMaxDepth()))\n",
    "        print('ROC-AUC = ' + str(np.mean(pipelineModel.avgMetrics)))\n",
    "        print('')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Evalúo Random Forest con lista amplia de hiper-parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASO BASE\n",
      "------------------------\n",
      "Features: scaledFeatures\n",
      "Hiper-parámetros óptimos:\n",
      "numTrees = 200\n",
      "maxDepth = 10\n",
      "ROC-AUC = 0.8074997580402385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_numTrees = {'BASE': [50, 200, 300],\n",
    "                  'CHI-CUADRADO-05': [50, 200, 300],\n",
    "                  'CHI-CUADRADO-01': [50, 200, 300],\n",
    "                  'PCA-k5': [50, 200, 300],\n",
    "                  'PCA-k10': [50, 200, 300]}\n",
    "\n",
    "param_maxDepth = {'BASE': [5, 10, 15],\n",
    "                 'CHI-CUADRADO-05': [5, 10, 15],\n",
    "                 'CHI-CUADRADO-01': [5, 10, 15],\n",
    "                 'PCA-k5': [5, 10, 15],\n",
    "                 'PCA-k10': [5, 10, 15]}\n",
    "    \n",
    "evualua_modelo_RF(param_numTrees, param_maxDepth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Evalúo Random Forest con fine-tuning de hiper-parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_numTrees = {'BASE': [10, 40, 80],\n",
    "                  'CHI-CUADRADO-05': [10, 40, 80],\n",
    "                  'CHI-CUADRADO-01':  [10, 40, 80],\n",
    "                  'PCA-k5': [10, 40, 80],\n",
    "                  'PCA-k10': [10, 40, 80]}\n",
    "\n",
    "param_maxDepth = {'BASE': [5, 10, 15],\n",
    "                 'CHI-CUADRADO-05': [5, 10, 15],\n",
    "                 'CHI-CUADRADO-01': [5, 10, 15],\n",
    "                 'PCA-k5': [5, 10, 15],\n",
    "                 'PCA-k10': [5, 10, 15]}\n",
    "    \n",
    "evualua_modelo_RF(param_numTrees, param_maxDepth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hiper-parámetro numTrees es el número de árboles que serán creados. Un valor alto puede provocas overfitting, mientras que uno bajo puede dar lungar al underfitting. El valor óptimo encontrado es XXXX.\n",
    "\n",
    "El hiper-parámetro maxDepth representa la profundidad máxima de cada árbol. También en este caso, un valor muy alto causa overfitting. El valor óptimo encontrado es XXXX.\n",
    "\n",
    "La mejor eficacia la obtuve con el caso sin selección ni extracción de variables (BASE). Esto tiene sentido, ya que los algoritmos basados en árboles de decisiones tienen integrada la selección de las variables más predictivas.\n",
    "\n",
    "ROC-AUC = 0.8294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
